{"meta":{"title":"Drinks","subtitle":"Coffee & Cola & Tea","description":null,"author":"Coltea","url":"http://1.15.107.122","root":"/"},"pages":[{"title":"about","date":"2021-03-24T12:46:46.000Z","updated":"2021-03-24T12:47:08.373Z","comments":false,"path":"about/index.html","permalink":"http://1.15.107.122/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Golang面试题","slug":"Interview/Go","date":"2021-12-07T09:25:11.000Z","updated":"2021-12-08T02:06:23.221Z","comments":true,"path":"2021/12/07/Interview/Go/","link":"","permalink":"http://1.15.107.122/2021/12/07/Interview/Go/","excerpt":"","text":"Go面试题[TOC] 编程基础nil 是变量名，而非关键字、保留字 可以覆盖（但不建议） 引用类型的零值 slice当slice的容量小于1024时，容量是按照2倍大小增长的。当容量大于1024，增长的容量是原来的1.25倍 rune类型中文长度判断 int32 new/make区别12func new(Type) *Typefunc make(t Type, size ...IntegerType) Type new：用于获取对应类型的指针类型,并进行内存分配置为零值 make：引用类型的初始化(slice，map、chan) 返回传入的类型,用于引用类型的内存空间分配 入参不同: make( )是slice，map、chan初始化 还可以加长度和容量 new( )是struct 只接受一个参数 返回 new 返回值是一个指针，指向新分配的该类型的零值, make 直接返回的是Type类型值。 1234567891011n1 := make([]A, 5)n2 := make([]*A, 5)n3 := new([]A)n4 := new([]*A)fmt.Println(n1, n1[0]) // [&#123; &#125; &#123; &#125; &#123; &#125; &#123; &#125; &#123; &#125;] &#123; &#125;fmt.Println(n2, n1[0]) // [&lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;] &#123; &#125;fmt.Println(n3) // &amp;[]fmt.Println(n4) // &amp;[] 引用类型/值类型 值类型 int string float bool struct 引用类型 chanel slice map interface 可以用make初始化 引用类型需要分配内存空间 Go是值传递还是引用传递全部是值传递，都是一个副本，一个拷贝。 但是因为拷贝的内容 有时候是非引用类型（int、string、struct等），这样就在函数中就无法修改原内容数据； 有的是引用类型（指针、map、slice、chan等），这样就可以修改原内容数据。 函数导入指针还是值 视情况而定 对原数据修改是指针，其他穿值 ​ （有外部调用会有逃逸 无关值类型还是指针类型） json数字默认解析为float64 触发异常的场景 空指针解析 下标越界 除数为0 主线程阻塞 死锁 deadelock 解析错误 未加断言 调用 panic 函数 导包顺序/多个init能否执行​ 执行顺序是按照导入包的顺序执行，而不是按照调用先后顺序执行。 ​ main开始 按顺序导包 import 然后按顺序执行init() 然后执行main函数代码 多核CPU场景下，cache如何保持一致、不冲突？设置状态 uint类型溢出1-2 = 2^64 -1 defer 、painc的执行顺序defer 的执行顺序是后进先出。当出现 panic 语句的时候，会先按照 defer 的后进先出的顺序执行，最后才会执行panic select可以用于什么？一个面向channel的 IO 监听操作,常用于gorotine的完美退出 错误处理是怎么做的?数组扩容实现append函数，因为slice底层数据结构是，由数组、len、cap组成，所以，在使用append扩容时，会查看数组后面有没有连续内存快，有就在后面添加，没有就重新生成一个大的数组。 golang中解析tag是怎么编程进阶读一个空管道或写一个缓冲已经满的管道，到底会发生什么行为 发生在非main协程里，则阻塞 发生在main协程里2.1 没有其他非main协程可以执行，报 fatal error: all goroutines are asleep - deadlock! 2.2 有其他非main协程可以执行，则main协程会让他们先执行 2.2.1 非main协在程执行过程中，帮main协程解除了阻塞 2.2.2 非main协执行结束后，依然没有帮main协程解除阻塞，则main协程报 fatal error: all goroutines are asleep - deadlock! 实现的？反射原理是什么？通过反射调用函数‘子程 panic 为何没法被父协程 recover defer 在多个协程之间是没有效果，在子协程里触发 panic，只能触发自己协程内的 defer，而不能调用 main 协程里的 defer 函数的。 性能优化 性能要求高（如用到cgo、文件） 可以加大p的数量runtime.GOMAXPROCS(GOMAXPROCS(0)+1) slice和map的容量初始化: 减少不断加元素时的扩容 减少反射 reflect.Value 会将对象拷贝并分配到堆上，程序中的对象都是消息体，有的消息体会超大，因此会分配较多的堆内存。 GOGC=100调大（内存要足够大） 降低gc除非频率 golang 的 gc 时机是根据当前与上次的 heap size 的比例来决定 一点点拷贝胜过传指针: 对象在栈上分配, 减少GC频率. 全局缓存对象有大量的key的情况, value少用指针GC并发Mark需要mark存活的对象, 如果value里指针多, 导致mark消耗的CPU很大, 使用一个struct内嵌数据消除指针. pprof10ms/次收集 CPU profile：报告程序的 CPU 使用情况，按照一定频率去采集应用程序在 CPU 和寄存器上面的数据 Memory Profile（Heap Profile）：报告程序的内存使用情况 Block Profiling：报告 goroutines 不在运行状态的情况，可以用来分析和查找死锁等性能瓶颈 Goroutine Profiling：报告 goroutines 的使用情况，有哪些 goroutine，它们的调用关系是怎样的 runtime/pprof主要用于可结束的代码块，如一次编解码操作等； net/http/pprof是对runtime/pprof的二次封装，主要用于不可结束的代码块，如web应用等。 heap空间分析 函数执行时间 svg的文件，用浏览器打开就是火焰图 tracego tool trace，可以看到 p 绑定的 g 实际的 GC 动作和相应时长，以及阻塞时间 SyncWaitGroup用于 多个 Goroutine 并发执行等待返回 1234type WaitGroup struct &#123; noCopy noCopy // 保证 sync.WaitGroup 不会被开发者通过再赋值的方式拷贝； state1 [3]uint32 // 存储着状态和信号量；&#125; 实现超时控制 time,after context.WithTimeout() Mutex是悲观锁还是乐观锁？悲观锁、乐观锁是什么？悲观锁 读写都是互斥 乐观锁本质不是锁 只是 乐观锁实现 不能保证先进先出 没法做到线程安全 Mutex有几种模式？ 正常模式 有抢占的机制 被唤起的 Goroutine 与新创建的 Goroutine 竞争(被唤起的 Goroutine大概率会获取不到锁) 饥饿模式 新的 Goroutine 在该状态下不能获取锁、也不会进入自旋状态，它们只会在队列的末尾等待 严格的先来后到 全部都要排队 直接走队列先进先出 饥饿模式的能避免 Goroutine 由于陷入等待无法获取锁而造成的高尾延时。 Mutex什么时候 进入/退出 饥饿模式？ 进入饥饿模式 当队列头部超过1ms获取不到锁的时候 退出饥饿模式 队列为空 队列第一个锁获得时间小于1ms Mutex可以做自旋锁吗？ 可以 项目中用过的锁？信号量信号量做并发量限制。 Go并发控制 全局共享变量加个互斥锁 channel通信 Context包 Channel介绍一下channel缓冲 无缓存,同步,需要先有一个消费者 没有消费者先启动， 会导致死锁阻塞 有缓冲,异步 基于环形缓存的传统生产者消费者模型； csp 在栈上的一个指向堆上的指针 channel实现原理runtime库里的一个结构体，是一个用于同步和通信的有锁队列 12345678910111213141516171819202122type hchan struct &#123; qcount uint // Channel 中的元素个数； dataqsiz uint // Channel 中的循环队列的长度； buf unsafe.Pointer // Channel 的缓冲区数据指针； elemsize uint16 // Channel 能够收发的元素大小 closed uint32 elemtype *_type // Channel 能够收发的元素类型 sendx uint // Channel 的发送操作处理到的位置； recvx uint //Channel 的接收操作处理到的位置； recvq waitq // 接受等待队列 sendq waitq // 发送等待队列 lock mutex // 用于保护成员变量的互斥锁 mutex 来保证线程安全,使用互斥锁解决程序中可能存在的线程竞争问题,容易地实现有锁队列。 悲观互斥锁&#125;type waitq struct &#123; first *sudog last *sudog&#125; // 表示一个在等待列表中的 Goroutine，该结构中存储了两个分别指向前后 runtime.sudog 的指针以构成链表。 用于保护成员变量的互斥锁 mutex 来保证线程安全,使用互斥锁解决程序中可能存在的线程竞争问题,容易地实现有锁队列。 有缓冲的数组 有字段来标记缓冲的队列长度 双指针 环形队列 channel是否线程安全？ 这个可以看源码就知道channel内部维护了一个互斥锁，来保证线程安全： 原子操作 CSP 悲观互斥锁 只有一个goroutine 能拿到这个锁 Channel分配在栈上还是堆上？堆上 ​ GMP调度在计算机中是分配工作所需资源的方法. linux的调度为CPU找到可运行的线程. 而Go的调度是为M(线程)找到P(内存, 执行票据)和可运行的G. 介绍一下GMPG:Goroutine(用户态轻量线程) 栈初始2KB, 调度不涉及系统调用. 用户函数调用前会检查栈空间是否足够, 不够的话, 会进行栈扩容 P:Processor(中间逻辑处理调度器) M:Machine Tread（操作系统分配到go的内核线程数） p的本地队列为空为自旋线程（过度状态 很快从全局或者work stealing 拿g） GMP线程模型 1:1 协程的创建、删除和切换的都由CPU完成，CPU开销过高 1:M 无法利用多核、线程阻塞会导致所有协程阻塞 M:N 实现复杂 GMP流程 初始化 创建G0 创建goroutine 放入队列 优先本地队列 本地满了放全局队列 M通过P获取G 1/62 全局 本地队列 全局队列 偷其他队列 4.执行 goroutine介绍一下goroutine 内存消耗更少： Goroutine所需要的内存通常只有2kb，而线程则需要1Mb（500倍）。最大1GB 创建与销毁的开销更小 由于线程创建时需要向操作系统申请资源，并且在销毁时将资源归还，因此它的创建和销毁的开销比较大。相比之下，goroutine的创建和销毁是由go语言在运行时自己管理的，因此开销更低。 切换开销更小 这是goroutine于线程的主要区别，也是golang能够实现高并发的主要原因。线程的调度方式是抢占式的，如果一个线程的执行时间超过了分配给它的时间片，就会被其它可执行的线程抢占。在线程切换的过程中需要保存/恢复所有的寄存器信息，比如16个通用寄存器，PC（Program Counter），SP（Stack Pointer），段寄存器等等。 而goroutine的调度是协同式的，它不会直接地与操作系统内核打交道。当goroutine进行切换的时候，之后很少量的寄存器需要保存和恢复（PC和SP）。因此gouroutine的切换效率更高。 G0/M0的用途G0 M启动后创建的第一个G就是G0，每个M都会有一个自己的G0 仅用于负责调度，G0不指向任何可执行的函数。 在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。 M0 主线程，实例 runtime.m0 执行初始化操作和启动第一个G（即G0）， 在之后M0就和其他的M一致。 Goroutine调度顺序 放 优先放本地队列 —&gt; 满了 —&gt; 全局队列 取 第一步，从全局运行队列中寻找goroutine。 为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。 第二步，从工作线程本地运行队列中寻找goroutine。 如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。 第三步，从全局运行队列中寻找goroutine。 第四步，从其它工作线程的运行队列中偷取goroutine。 如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。 Goroutine的状态 Goroutine自旋占用cpu如何解决（go调用、gmp）Goroutine抢占时机（gc 栈扫描）STW的时候 goroutine什么时候会发生阻塞? 由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine； 由于网络请求和 IO 操作导致 Goroutine 阻塞。 Go 程序提供了网络轮询器（NetPoller）来处理网络请求和 IO 操作的问题，其后台通过 kqueue（MacOS），epoll（Linux）或 iocp（Windows）来实现 IO 多路复用。通过使用 NetPoller 进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用时阻塞 M。这可以让 M 执行 P 的 LRQ 中其他的 Goroutines，而不需要创建新的 M。执行网络系统调用不需要额外的 M，网络轮询器使用系统线程，它时刻处理一个有效的事件循环，有助于减少操作系统上的调度负载。用户层眼中看到的 Goroutine 中的“block socket”，实现了 goroutine-per-connection 简单的网络编程模式。实际上是通过 Go runtime 中的 netpoller 通过 Non-block socket + I/O 多路复用机制“模拟”出来的。 当调用一些系统方法的时候（如文件 I/O） ，如果系统方法调用的时候发生阻塞，这种情况下，网络轮询器（NetPoller）无法使用，而进行系统调用的 G1 将阻塞当前 M1。调度器引入 其它M 来服务 M1 的P。 如果在 Goroutine 去执行一个 sleep 操作导致 M 被阻塞了。Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。 Go 中的阻塞分析有助于您分析程序在等待下列阻塞操作上的花费时间： select chan send chan receive semacquire ( Mutex.Lock, RWMutex.RLock , RWMutex.Lock, WaitGroup.Wait) notifyListWait ( Cond.Wait) 只有当 Go 通过将 goroutine 置于等待状态来暂停执行时，时间才会被跟踪。例如 Mutex.Lock()，如果锁可以立即或通过少量自旋被获得，那么这样的操作将不会出现在您的分析结果中。 上面的操作是 Go 运行时使用的等待状态的子集，下面的操作将不会出现在分析文件中： time.Sleep（但是 time.After, time.Tick 和其他封装了 channel 的操作会显示出来） 垃圾回收 系统调用（例如网络 I/O，文件 I/O 等） 运行时内部锁（例如 stopTheWorld） cgo 阻塞调用 永远阻塞的事件（例如在 nil 通道上发送/接收） 阻止尚未完成的事件 在某些场景下， Goroutine Profiling (debug=2) 可能是阻塞分析的一个很好的文档，因为它涵盖了所有等待状态，并且可以显示尚未完成且正在进行的阻塞事件。 goroutine阻塞了怎么办 原子、互斥量或通道、网络请求和 IO 操作、sleep 调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine 当调用一些系统方法的时候 syscall（如文件 I/O）， 而进行系统调用的 G将阻塞当前 M。调度器引入 其它M 来服务 M1 的P。 sleep Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。 goroutine抢占的还是协作的 怎么实现抢占 sysmon 当一个协程运行超过 10ms 时，Go 会尝试抢占它。10-20ms 线程协程映射关系/线程模型 1:N: 无法利用多核、线程阻塞会导致所以协程阻塞 1:1: 协程的创建、删除和切换的都由CPU完成，CPU开销过高、 M:N: 好用但是实现复杂 Processor​ 上下文的逻辑处理调度器 ​ 每个p有一个自己的本地goroutine队列 复用线程 避免频繁销毁创建，提高复用率 work stealing机制 当本线程无可运行的G时，尝试从其他线程绑定的P偷取G。 hand off机制 当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。 利用并行 GOMAXPROCS利用多核CPU GOMAXPROCS利用多核CPU 抢占策略 goroutine最多占用CPU 10ms， coroutine要等待协程主动释放 全局队列 work stealing从其他P偷不到G时，它可以从全局G队列获取 GCGc的类型 引用计数：对每个对象维护一个引用计数，当引用该对象的对象被销毁时，引用计数减1，当引用计数器为0是回收该对象。 优点：对象可以很快的被回收，不会出现内存耗尽或达到某个阀值时才回收。 缺点：不能很好的处理循环引用，而且实时维护引用计数，有也一定的代价。 代表语言：Python、PHP、Swift 标记-清除：从根变量开始遍历所有引用的对象，引用的对象标记为”被引用”，没有被标记的进行回收。 优点：解决了引用计数的缺点。 缺点：需要STW，即要暂时停掉程序运行。 代表语言：Golang(其采用三色标记法) 介绍一下三色标记法减少了STW的时间，即时标记，与程序并发执行 流程 所有对象最开始都是白色. 从root对象(栈对象和全局变量)开始找到可达对象，标记为灰色，放入待处理队列。 遍历灰色对象队列，将其引用对象标记为灰色放入待处理队列，自身标记为黑色。 循环步骤3直到灰色队列为空为止， 结束时所有引用对象都被标记为黑色，所有不可达对象为白色， 对剩下的白色进行回收 介绍一下混合写屏障为了解决误清扫 ​ 黑色对象创建新对象会变成白色，而黑色不是灰色一样会被扫描到 原理 强三色不变式 黑色不允许引用白色 弱三色不变式 黑色引用白色时白色上层需要有灰色 屏障机制 插入屏障 黑色下游必须为灰色 删除屏障 并发标记和清扫 内存耗尽，挂起程序，清扫所有未被引用的对象 非分代和非紧缩 Golang中的混合写屏障满足弱三色不变式，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持， Gc触发时机 gcTriggerAlways（废弃）：强制触发GC gcTriggerHeap：当前分配的内存达到一定阈值时触发，这个阈值在每次GC过后都会根据堆内存的增长情况和CPU占用率来调整 gcTriggerTime：当一定时间没有执行过GC就触发GC（2分钟） gcTriggerCycle：调用runtime.GC() Go内存管理方式Go哪些对象分配在堆上，哪些对象分配在栈上？逃逸分析(escape analysis)，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。 栈上-局部变量 堆上-全局、大内存变量 介绍一下大对象小对象，为什么小对象多了会造成gc压力？​ 通常小对象过多会导致GC三色法消耗过多的GPU。优化思路是，减少对象分配 内存类似于TCMalloc的结构 最小8B 最大 32KB 局部对象是分配到栈上还是分配到堆上，返回一个引用安全吗Golang 中的变量只要被引用就会一直存活，Golang 编译器会将函数的局部变量分配到栈帧上，如果编译器不能确保变量return 后不再被引用，那么编译器会将它分配到堆上。所以这里返回一个引用是安全的。 并且如果局部变量非常大，那么它需要被分配在堆上而不是栈上。 并且Go 分成了微对象(0，16B)、小对象(16B,32KB)、大对象(32KB ,+∞)，微对象通过微分配器提高分配的性能，大对象会分配到栈上。 内存分区 arena 堆区，go runtime 在动态分配的内存都在这个区域，并且将内存块分成 8kb 的页，一些组合起来的称为 bitmap 用来标记堆区使用的映射表，它记录了哪些区域保存了对象，对象是否包含指针，以及 GC 的标记信息. spans 存放 mspan 的指针，根据 spans 区域的信息可以很容易找到 mspan. 它可以在 GC 时更快速的找到的大块的内存 mspan. 堆栈分别存储什么？ 栈 编译器管理 一级缓存 自动申请、分配、释放。一般不会太大，我们常见的函数参数（不同平台允许存放的数量不同），局部变量等等都会存放在栈上 函数调用的局部对象、变量 堆 人为管理 二级缓存 手动申请、分配、释放。一般所涉及的内存大小并不定，一般会存放较大的对象。另外其分配相对慢，涉及到的指令动作也相对多，GC会回收，引用类型一般都分配到堆上。 全局的对象、channel、需要共享的数据、超出分配的内存空间 内存逃逸编译时确定对象被分配到堆上还是栈上，这个步骤叫逃逸分析 golang程序变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配。 确认逃逸在编译阶段 确认变量的存放位置（堆还是栈）, 尽量放在栈上 全部在堆上 垃圾回收（GC）的压力不断增大 申请、分配、回收内存的系统开销增大（相对于栈） 动态分配产生一定量的内存碎片 OOM内存溢出 pprof，拿到内存分布图 gc在标记清除后，不会立马把空闲的内存还给系统，而是等待5分钟后的scvg来释放内存。 慢增型 http、db、长连接 close 突增型 内存泄露或新增大量内存占用的逻辑(例：过长的字符串) go无法分配内存时 throw输出的协程栈pprof调试 结合火焰图, 查看影响性能的热点部分 火焰图 调用栈,长度代表cpu时长。 其他如何实现 deepcopy 深度拷贝可以通过序列化和反序列化来实现， val := reflect.ValueOf(v) 拿到 v 的反射值 也可以基于reflect包的反射机制完成。 reflect.DeepEqual 检查 ​","categories":[{"name":"Interview","slug":"Interview","permalink":"http://1.15.107.122/categories/Interview/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://1.15.107.122/tags/Go/"}]},{"title":"","slug":"alog/归并排序","date":"2021-11-05T08:22:32.863Z","updated":"2021-11-05T08:22:32.863Z","comments":true,"path":"2021/11/05/alog/归并排序/","link":"","permalink":"http://1.15.107.122/2021/11/05/alog/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Redis持久化策略","slug":"redis/Redis持久化策略","date":"2021-04-01T08:48:00.000Z","updated":"2021-04-01T08:48:30.678Z","comments":true,"path":"2021/04/01/redis/Redis持久化策略/","link":"","permalink":"http://1.15.107.122/2021/04/01/redis/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5/","excerpt":"","text":"Redis持久化策略问题 宕机了，Redis如何避免数据丢失？ AOF 日志是如何实现的？ AOF日志过大怎么解决？ AOF 重写会阻塞吗? 快照时数据能修改吗? 相对比较好的持久化策略 三点建议： 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。 RDBRDB(内存快照): 原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化。 相对于大数据集，RDB的启动效率会更高。 fork出一个子进程同步数据 子进程共享主进程数, 不阻塞主进程数据，主进程在修改数据时会创建副本 子进程读副本，fork创建会阻塞主进程（涉及内存共享） Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。 save：在主线程中执行，会导致阻塞； bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。 但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。 bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。 为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。 AOF(Append Only File)AOF原理是将Reids的操作日志以追加的方式写入文件 。 先处理后写，1.避免错误日志 2.不会阻塞操作，3.避免写完日志后宕机 通常文件更大、恢复更慢、牺牲部分性能换取更高的缓存一致性 AOF 重写不阻塞 后台子进程 bgrewriteaof处理 AOF 配置 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； 影响性能 Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 AOF工作原理1、Redis 执行 fork() ，现在同时拥有父进程和子进程。2、子进程开始将新 AOF 文件的内容写入到临时文件。3、对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾,这样样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。4、当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。5、搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF 重写 auto-aof-rewrite-min-size: 表示运行AOF重写时文件的最小大小，默认为64MB auto-aof-rewrite-percentage: 这个值的计算方法是：当前AOF文件大小和上一次重写后AOF文件大小的差值，再除以上一次重写后AOF文件大小。也就是当前AOF文件比上一次重写后AOF文件的增量大小，和上一次重写后AOF文件大小的比值。 AOF文件大小同时超出上面这两个配置项时，会触发AOF重写。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://1.15.107.122/categories/Redis/"}],"tags":[{"name":"NoSQL","slug":"NoSQL","permalink":"http://1.15.107.122/tags/NoSQL/"},{"name":"Database","slug":"Database","permalink":"http://1.15.107.122/tags/Database/"}]},{"title":"阿里外包（Python）笔试题","slug":"阿里外包","date":"2021-03-29T02:19:24.419Z","updated":"2021-03-29T02:28:01.925Z","comments":true,"path":"2021/03/29/阿里外包/","link":"","permalink":"http://1.15.107.122/2021/03/29/%E9%98%BF%E9%87%8C%E5%A4%96%E5%8C%85/","excerpt":"","text":"1.linux12345678910111213141516171819ll -hmkdircdscphtopiftoptail -f app.logvi XX.lsof -i:80pingtelnet ip portyum installps -ef|grep pythonkillall &lt;PROCRESS&gt;kill -9 &lt;PID&gt;ssh root@&lt;HOST&gt;curl &lt;&gt;chmod 777 &lt;&gt;ln -s &lt;&gt; &lt;&gt; cat filename.log |grep ‘login’|wc -l 2.SQL123select distinct name from student where score&gt;95;select count(distinct name) from student where score&gt;95;select count(1) as ct,socre from student group by socre order by ct desc 3.编码数组操作12345def array_insert(array, n): for index, key in enumerate(array): if n &lt;= key: return index return len(array) 多线程锁及通信123456789101112131415161718192021222324252627282930313233343536373839404142import threadingdef target_a(counter=10): while counter: locka.acquire() print(&#x27;a&#x27;, end=&#x27;&#x27;) lockb.release() counter -= 1def target_b(counter=10): while counter: lockb.acquire() print(&#x27;b&#x27;, end=&#x27;&#x27;) lockc.release() counter -= 1def target_c(counter=10): while counter: lockc.acquire() print(&#x27;c&#x27;, end=&#x27;&#x27;) locka.release() counter -= 1if __name__ == &#x27;__main__&#x27;: locka = threading.Lock() lockb = threading.Lock() lockc = threading.Lock() lockb.acquire() lockc.acquire() t1 = threading.Thread(target=target_a) t2 = threading.Thread(target=target_b) t3 = threading.Thread(target=target_c) t1.start() t2.start() t3.start() 快排123456789101112def quick_sort(lt): if len(lt) &lt;= 1: return lt mid = lt[len(lt) // 2] lt.remove(mid) left_lt, right_lt = [], [] for i in lt: if i &lt;= mid: left_lt.append(i) if i &gt; mid: right_lt.append(i) return quick_sort(left_lt) + [mid] + quick_sort(right_lt) 找两数之和12345678910111213def find_sum(lt, n): dt = &#123;i: e for e, i in enumerate(lt) if n - i &lt;= i&#125; res = [] for e, i in enumerate(lt): if n - i in dt: if e != dt[n - i]: res.append([n - i, i]) return resif __name__ == &#x27;__main__&#x27;: r = find_sum([0, 1, 3, 9, 7, 2, 8, 4, 5, 5], 10) print(r) 发散题接口耗时长-排查及优化time.time()打点找出运行慢的那一块代码，然后具体问题具体分析 问题处理 代码bug: 修bug 多个IO请求等待: 开多线程池请求 cpu密集型计算： 考虑开多进程处理或者c++重写 py调用 数据库查询慢: 用explain 看走没走索引 没有的话 对应字段 建索引 force index 强制走索引查询 数据库内存 cpu压力不正常 查看占用高的sql 优化 或者升级 查看show processlist 查看是不是有过多或者慢查询占用内存和cpu 再kill ddl语句锁表表结构重构中导致不能查询 sql语句优化 减少like join表 !=，乱建索引，select * 优化 消息队列 与接口返回无关的一系列操作可以考虑异步 redis或者mq消息队列处理，单生产者接入多消费者 redis加缓存 Url请求返回 url解析成ip : /etc/hosts + DNS 网络层 ip协议 arp协议 mac地址查询 传输层 TCP 连接：TCP 三次握手 应用层 HTTP 连接: 发送 HTTP 请求 服务器监听对应端口 处理请求 nginx负载均衡分发 静态页面直接返回 部分动态页面转发到服务器对应端口 k8s、docker监听端口处理 python网关服务器处理(ASGI/WSGI) uWSGI/gunicorn/uvicorn 框架处理（flask/django/fastapi）解析http报文 json/text/file返回 查询redis缓存/mysql 组装数据并返回 HTTP 报文 浏览器解析渲染页面/前端直接处理的json/xml数据 断开连接：TCP 四次挥手","categories":[{"name":"面试","slug":"面试","permalink":"http://1.15.107.122/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://1.15.107.122/tags/Python/"},{"name":"面试","slug":"面试","permalink":"http://1.15.107.122/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Python面试题","slug":"Interview/Python","date":"2021-03-27T15:26:11.000Z","updated":"2021-12-08T02:06:23.225Z","comments":true,"path":"2021/03/27/Interview/Python/","link":"","permalink":"http://1.15.107.122/2021/03/27/Interview/Python/","excerpt":"","text":"Python面试题[TOC] 基础args/kwargsargs 不定数量的输入参数 kwargs 不定数量的键值对输入参数 *args必须在**kwargs前面 创建类 带上project生成器/迭代器迭代器 记录计算方法 不实际存储列表数据到内存中，是一种延迟计算方法， range函数实现的就是一种迭代器 生成器 本质也是一种迭代器，yield语句 就是用于迭代操作（for 循环）的对象，何实现了 __next__ 方法 不需要像列表把所有元素一次性加载到内存，而是以一种延迟计算方式返回元素 生成器 函数加上 yiled参数 生成器本质上也是一个迭代器 生成器表达式用（） Generator 是一个用于创建迭代器的简单而强大的工具。 它们的写法类似标准的函数，但当它们要返回数据时会使用 yield 语句。类似 go里面channel通道接受io、 迭代器 节省内存, 每次生成一个元素, 而不是先计算出所有的元素, 保存下来. 装饰器解决重复性的操作，功能抽离 计算函数运行时间 给函数打日志 类型检查 打开db的连接 is和 == 的区别is是比较对象的id，而==仅比较对象的值， 数据结构 dict-hashmap list-链表 tuple- set 魔法方法 __add__ __dict__ 下划线开头函数__init__ / __new__ init是初始化方法 实例方法，new是构造方法 静态方法 new在init之前执行, 用于创建对象并返回对象（可返回实例如不可变对象） init返回None、new返回对象或者实例 绝大多数情况下，我们都不需要自己重写__new__方法，但在当继承一个不可变的类型（例如str类,int类等）时，则需要用到new。 __getter__ / __setter__ 编码区别 ascii unicode Utf-8 模块查找顺序 内置的模块（python解释器自带的） 第三方（开发者编写的模块） 自定义的模块（自己编写的模块） with关键词__ENTER __END 进阶协程 N:1，Python协程模式，多个协程在一个线程中切换。在IO密集时切换效率高，但没有用到多核 协程通信是并发 不会并行 因为在单线程内执行 所以线程安全不需要考虑互斥 性能优化 c扩展 pypy profile查看性能热点 非cpu密集型用异步、多线程 火焰图 profile_line 正则 贪婪与非贪婪 GC 循环应用导致引用计数无法清零、导致GC无法进行垃圾回收 函数默认参数使用引用类型(dict、list) 多线程 async await flask context 存在GIL，为什么还要加现场锁GIL的线程安全是针对他自身Cpython的接口、字节码是按顺序执行的 （比如GC的应用计数） 并非用户态的代码是线程安全的的 用户的线程是可以切换执行的 进程/线程/协程进程下的多个线程可以共享该进程的所有资源，进程之间相互独立 多进程:cpu密集走进程,进程资源开销大，但相对稳定 **多线程:**io 密集走线程,python 有gil多线程只能发挥单核的性能 在CPU密集的程序中，线程有点鸡肋，无法发挥多处理器的效率，这一点可以用进程来做。 在IO 密集的程序中，大量时间都花在等待IO上，对CPU不敏感，线程可以很好的胜任。 编程题字典按key排序1234alist = [&#123;&#x27;name&#x27;:&#x27;a&#x27;,&#x27;age&#x27;:20&#125;,&#123;&#x27;name&#x27;:&#x27;b&#x27;,&#x27;age&#x27;:30&#125;,&#123;&#x27;name&#x27;:&#x27;c&#x27;,&#x27;age&#x27;:25&#125;] def sort_by_age(list1): return sorted(alist,key=lambda x:x[&#x27;age&#x27;],reverse=True) 装饰器实现单例GCPython内部使用引用计数，来保持追踪内存中的对象，所有对象都有引用计数。 引用计数增加的情况： 1，一个对象分配一个新名称 2，将其放入一个容器中（如列表、元组或字典） 引用计数减少的情况： 1，使用del语句对对象别名显示的销毁 2，引用超出作用域或被重新赋值 1，当一个对象的引用计数归零时，它将被垃圾收集机制处理掉。 2，当两个对象a和b相互引用时，del语句可以减少a和b的引用计数，并销毁用于引用底层对象的名称。然而由于每个对象都包含一个对其他对象的应用，因此引用计数不会归零，对象也不会销毁。（从而导致内存泄露）。为解决这一问题，解释器会定期执行一个循环检测器，搜索不可访问对象的循环并删除它们。 内存溢出问题 对象一直被全局变量所引用, 全局变量生命周期长. 垃圾回收机被禁用或者设置成debug状态, 垃圾回收的内存不会被释放. 内存池机制Python提供了对内存的垃圾收集机制，但是它将不用的内存放到内存池而不是返回给操作系统。 1，Pymalloc机制。为了加速Python的执行效率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。 内置函数 with __enter__ 和 __exit__ 方法 元类​ 相当于类的父类 用于创建类。python所以的东西都是对象，都是从一个类里面创建出来的，type就是python的内建元类。 django 用元类实现插件化与语法糖 asyncio​ 异步非阻塞，内部可以await 停止做其他的操作比如网络 ​ fastapi 私有变量 约定俗成、不是强制 装饰器抽离出大量函数中与函数功能本身无关的雷同代码并继续重用 日志 资源开销型 with外写 Flaskcurrent_app 是应用上下文。应用程序运行过程中，保存的一些配置信息， request、session 是请求上下文。保存了客户端和服务器交互的数据。 设计模式单例 装饰器 123456789101112131415def singleton(cls): instances = &#123;&#125; def wrapper(*args, **kwargs): if cls not in instances: instances[cls] = cls(*args, **kwargs) return instances[cls] return wrapper @singleton class Foo(object): pass foo1 = Foo() foo2 = Foo() print(foo1 is foo2) # True 使用基类，重写__new__方法 使用元类，type + metaclass 多重继承搜索从父类所继承属性的操作是深度优先、从左至右、递归查找。 派生类方法覆盖重载基类 Classmethod / staticmethod​ 相同 都不需要实例化，即可调用 类方法需要cls参数传入，静态函数则不用 区别 类函数可以当做作为类似__new__一样的构造函数，用来返回类对象","categories":[{"name":"Interview","slug":"Interview","permalink":"http://1.15.107.122/categories/Interview/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://1.15.107.122/tags/Python/"}]},{"title":"MySQL","slug":"backend/MySQL","date":"2021-03-27T15:13:11.000Z","updated":"2021-03-27T15:16:19.623Z","comments":true,"path":"2021/03/27/backend/MySQL/","link":"","permalink":"http://1.15.107.122/2021/03/27/backend/MySQL/","excerpt":"","text":"MySQLSQL123456789101112131415161718192021222324252627282930313233343536373839404142434445# 从不订购的客户select a.Name as Customers from Customers aleft join Orders b on a.Id&#x3D;b.CustomerId Where b.Id is null select a.Name as &#96;Customers&#96; from Customers awhere id not in (select distinct CustomerId from Orders)# 总分前三的学生姓名SELECT &#96;name&#96; from ( SELECT b.&#96;name&#96;,SUM(a.score) from score a join student b on a.student_id&#x3D;b.id GROUP BY b.&#96;name&#96; ORDER BY SUM(a.score) desc limit 3) as t# 每门课成绩前五名SELECT a.class,a.&#96;name&#96;,a.score from grade a WHERE (SELECT COUNT(1) from grade b WHERE a.class&#x3D;b.class and a.score &lt;b.score)&lt;5ORDER BY class,score descSELECT a.class,a.&#96;name&#96;,a.score ,COUNT(b.score) as &quot;No&quot; from grade a left join grade b on a.class&#x3D;b.class and a.score&lt; b.scoreGROUP BY a.class,a.&#96;name&#96;,a.scoreHAVING COUNT(b.score) &lt;5ORDER BY a.class,a.score desc# 获取所有部门中当前员工薪水最高的相关信息select r.dept_no,ss.emp_no,r.maxSalary from ( select d.dept_no,max(s.salary)as maxSalary from dept_emp d,salaries s where d.emp_no&#x3D;s.emp_no group by d.dept_no)as r,salaries ss,dept_emp ddwhere r.maxSalary&#x3D;ss.salary and r.dept_no&#x3D;dd.dept_no and dd.emp_no&#x3D;ss.emp_noorder by r.dept_no asc 为什么用id做主键？ 行内约定规范（例如阿里官方的java开发手册 id、create_time、update_time 是表的必备字段，其中id为主键） 可以唯一标识一行， 数据自增 id 是顺序的，可以保证索引树上的数据比较紧凑，有更高的空间利用率以及减少数据页的分裂合并等操作，提高效率。 空间占用相对较少 整型做主键，则只要4个字节 利于回表：先在二级索引查询到对应的主键值，然后根据主键再去聚簇索引里面取查询。其他的唯一索引例如手机号、身份证号作为主键等可能比较长 32 事务ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性） 脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read） 隔离级别数据库事务transanction正确执行的四个基本要素。ACID,原子性(Atomicity)、一致性(Correspondence)、隔离性(Isolation)、持久性(Durability)。 原子性:整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性:在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。 隔离性:隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行 相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请 求，使得在同一时间仅有一个请求用于同一数据。 持久性:在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 【脏读】读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 【不可重复读】读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 【幻读】可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 可串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 不可重复读指的是数据修改、幻读指的是数据增加不涉及修改 MVCC就是多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问。 MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作。","categories":[{"name":"Database","slug":"Database","permalink":"http://1.15.107.122/categories/Database/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://1.15.107.122/tags/Database/"}]},{"title":"操作系统","slug":"backend/操作系统","date":"2021-03-27T15:13:11.000Z","updated":"2021-03-27T15:28:03.024Z","comments":true,"path":"2021/03/27/backend/操作系统/","link":"","permalink":"http://1.15.107.122/2021/03/27/backend/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"操作系统操作系统概述​ 硬件进行抽象和管理，对应用进行服务和管理 进程线程 进程：资源分配的基本单位，执行程序的实例。 线程：cpu调度的基本单元，同进程下的线程共享资源。 协程：协程是一种用户态的轻量级线程，协程程序主动控制切换，没有切换的开销，所以执行效率极高，。 并发: 并行: 微观上只有一个核心只能同时执行一个进程， 线程与同属一个进程的其他的线程共享进程所拥有的全部资源 状态​ 新生、预备、阻塞、运行、终止 进程通信 管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 有名管道 (namedpipe) ：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 信号量(semophore ) ：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 消息队列( messagequeue ) ：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号 (sinal ) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 共享内存(shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 套接字(socket ) ：套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。 ​ 双工(Half Duplex)数据传输指数据可以在一个信号载体的两个方向上传输，但是不能同时传输 线程通信 锁机制：包括互斥锁、条件变量、读写锁互斥锁提供了以排他方式防止数据结构被并发修改的方法。读写锁允许多个线程同时读共享数据，而对写操作是互斥的。条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量 信号机制(Signal)：类似进程间的信号处理线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。 死锁​ 多个线程竞争有限数量的资源，自己持有某种资源又等待其他资源释放，一直在保持这种状态，称为死锁。 ​ ​","categories":[{"name":"ComputerScience","slug":"ComputerScience","permalink":"http://1.15.107.122/categories/ComputerScience/"}],"tags":[{"name":"CS","slug":"CS","permalink":"http://1.15.107.122/tags/CS/"}]},{"title":"计算机网络","slug":"backend/计算机网络","date":"2021-03-27T15:13:11.000Z","updated":"2021-03-27T15:28:03.028Z","comments":true,"path":"2021/03/27/backend/计算机网络/","link":"","permalink":"http://1.15.107.122/2021/03/27/backend/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"计算机网络url解析返回 ip解析:缓存(浏览器和操作系统)-/etc/hosts-根域名-顶级域名-权威(二级)域名 网络层 ip协议 arp协议 mac地址查询 传输层 TCP 连接：TCP 三次握手 应用层 HTTP 连接: 发送 HTTP 请求 cdn直接返回/非cdn服务器监听对应端口 处理请求 七层nginx负载均衡分发 静态页面直接返回 部分动态页面转发到服务器对应端口 k8s、docker监听端口处理 python网关服务器处理(ASGI/WSGI) uWSGI/gunicorn/uvicorn 框架处理（flask/django/fastapi）解析http报文 查询redis缓存/mysql 组装数据并返回 HTTP 报文 json/text/file返回 浏览器解析渲染页面/前端直接处理的json/xml数据 断开连接：TCP 四次挥手 网络协议1.host里面找ip没有从dns里面找 2.请求ip地址 建立连接、nginx静态模板-&gt;WSGI服务器 gunicorn -&gt;flask web application -&gt; 返回 应用层 FTP、DNS、Telnet、SMTP、HTTP 表示层 数据压缩，数据加密以及数据描述 会话层 DNS 传输层 tcp、udp 网络层 ip、ARP 数据链路层 PPP、FR、HDLC、VLAN、MAC （网桥，交换机） 物理层 IEEE （中继器，集线器，网关） ARP协议即地址解析协议（Address Resolution Protocol）， 用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址。 基于功能来考虑，ARP是链路层协议；基于分层/包封装来考虑，ARP是网络层协议。 Rpc/http区别http:有用信息占比少，毕竟HTTP工作在第七层，包含了大量的HTTP头等信息。其次是效率低，还是因为第七层的缘故. 基于Restful的远程过程调用有着明显的缺点，主要是效率低、封装调用复杂。当存在大量的服务间调用时，这些缺点变得更为突出。 DNSTcp 三次握手其中ACK报文是用来应答的，SYN报文是用来同步的 作用：确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备 第一次、第二次不携带数据，防止恶意攻击 第一次握手：客户端发送syn包(syn=x)到服务器，并进入SYN_SEND状态，等待服务器确认； 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。 握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。 Tcp四次挥手 与建立连接的“三次握手”类似，断开一个TCP连接则需要“四次挥手”。 第一次挥手：主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不 会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可 以接受数据。 第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）。 第三次挥手：被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。 第四次挥手：主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。 交换机 在计算机网络系统中，交换机是针对共享工作模式的弱点而推出的。交换机拥有一条高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背 部总线上，当控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部 交换矩阵迅速将数据包传送到目的端口。目的MAC若不存在，交换机才广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部地址表 中。 交换机工作于OSI参考模型的第二层，即数据链路层。交换机内部的CPU会在每个端口成功连接时，通过ARP协议学习它的MAC地址，保存成一张 ARP表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。因此，交换机可用于划分数据链路层广播，即冲突域；但它不 能划分网络层广播，即广播域。 交换机被广泛应用于二层网络交换，俗称“二层交换机”。 交换机的种类有：二层交换机、三层交换机、四层交换机、七层交换机分别工作在OSI七层模型中的第二层、第三层、第四层盒第七层，并因此而得名。 路由器 路由器（Router）是一种计算机网络设备，提供了路由与转送两种重要机制，可以决定数据包从来源端到目的端所经过 的路由路径（host到host之间的传输路径），这个过程称为路由；将路由器输入端的数据包移送至适当的路由器输出端(在路由器内部进行)，这称为转 送。路由工作在OSI模型的第三层——即网络层，例如网际协议。 路由器的一个作用是连通不同的网络，另一个作用是选择信息传送的线路。 路由器与交换器的差别，路由器是属于OSI第三层的产品，交换器是OSI第二层的产品(这里特指二层交换机)。 网关 网关（Gateway），网关顾名思义就是连接两个网络的设备，区别于路由器（由于历史的原因，许多有关TCP/IP 的文献曾经把网络层使用的路由器（Router）称为网关，在今天很多局域网采用都是路由来接入网络，因此现在通常指的网关就是路由器的IP），经常在家 庭中或者小型企业网络中使用，用于连接局域网和Internet。 网关也经常指把一种协议转成另一种协议的设备，比如语音网关。 在传统TCP/IP术语中，网络设备只分成两种，一种为网关（gateway），另一种为主机（host）。网关能在网络间转递数据包，但主机不能 转送数据包。在主机（又称终端系统，end system）中，数据包需经过TCP/IP四层协议处理，但是在网关（又称中介系 统，intermediate system）只需要到达网际层（Internet layer），决定路径之后就可以转送。在当时，网关 （gateway）与路由器（router）还没有区别。 在现代网络术语中，网关（gateway）与路由器（router）的定义不同。网关（gateway）能在不同协议间移动数据，而路由器（router）是在不同网络间移动数据，相当于传统所说的IP网关（IP gateway）。 网关是连接两个网络的设备，对于语音网关来说，他可以连接PSTN网络和以太网，这就相当于VOIP，把不同电话中的模拟信号通过网关而转换成数字信号，而且加入协议再去传输。在到了接收端的时候再通过网关还原成模拟的电话信号，最后才能在电话机上听到。 对于以太网中的网关只能转发三层以上数据包，这一点和路由是一样的。而不同的是网关中并没有路由表，他只能按照预先设定的不同网段来进行转发。网关最重要的一点就是端口映射，子网内用户在外网看来只是外网的IP地址对应着不同的端口，这样看来就会保护子网内的用户。","categories":[{"name":"ComputerScience","slug":"ComputerScience","permalink":"http://1.15.107.122/categories/ComputerScience/"}],"tags":[{"name":"CS","slug":"CS","permalink":"http://1.15.107.122/tags/CS/"}]},{"title":"Redis面试题","slug":"backend/Redis","date":"2021-03-24T03:49:11.000Z","updated":"2021-04-01T08:48:30.673Z","comments":true,"path":"2021/03/24/backend/Redis/","link":"","permalink":"http://1.15.107.122/2021/03/24/backend/Redis/","excerpt":"","text":"Redis概述特性 Redis为什么这么快？ Redis是单线程的，避免了多线程的上下文切换和并发控制开销； Redis大部分操作时基于内存，读写数据不需要磁盘I/O，所以速度非常快； Redis采用了I/O多路复用机制，提高了网络I/O并发性； Redis提供高效的数据结构，如跳跃表 o(logn) 、哈希表 o(1)等； 数据结构 String : 缓存、计数器、限速器、分布式锁、集群共享信息通用配置 List : 消息队列、底层双向链表 Set : 好友关系 zset(SortSet) :排行榜 Hash : Streams(流) : 业务场景 缓存 string 计数器 string 排行榜 Zset 异步消息队列 List 分布式锁 string EX seconds | PX milliseconds 共享信息、高频访问信息 如session 集合关系 好友关系 Set 分布式锁1SET key value [EX seconds | PX milliseconds] [NX] 分布式锁是由共享存储系统(redis就是其中一种)维护的变量，多个客户端可以向共享存储系统发送命令进行加锁或释放锁操作 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁； 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间； 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端。 持久化策略 RDB: 原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化。 相对于大数据集，RDB的启动效率会更高。 AOF: 原理是将Reids的操作日志以追加的方式写入文件。 通常文件更大、恢复更慢、牺牲部分性能换取更高的缓存一致性 架构模式 主从 1对多，非高可用性 哨兵 监控从切换成主数据库，浪费资源 集群 分布式存储，至少需要三主三从 数据淘汰机制 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 缓存 穿透:空值设置一个较短的缓存 击穿(业务狭隘):热门缓存失效 雪崩:短时间内缓存大量失效 时间后加随机值 缓存缓存穿透概念：当用户使用一个不存在的key进行查询时，缓存（redis）无法命中，需要访问数据库查询该数据，若数据库中没有数据，则不写入缓存（redis）中，这将导致不存在的数据每次请求都要去数据库查询，造成缓存穿透。 解决办法： 使用布隆过滤器，通过bloomfilter.mightContain(key)来判断当前key是否命中。布隆过滤器原理：https://zhuanlan.zhihu.com/p/43263751 当数据库查询结果为空时，在redis中将key对应的value设置空值，并设置一个较短的过期时间。 缓存雪崩缓存在同一时间内大量·键过期（失效），接着来的一大波请求瞬间都落在了数据库中导致连接异常。 解决方案： 1、也是像解决缓存穿透一样加锁排队，实现同上; 2、建立备份缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，A没有读B，并且更新A缓存和B缓存;","categories":[{"name":"Redis","slug":"Redis","permalink":"http://1.15.107.122/categories/Redis/"}],"tags":[{"name":"NoSQL","slug":"NoSQL","permalink":"http://1.15.107.122/tags/NoSQL/"},{"name":"Database","slug":"Database","permalink":"http://1.15.107.122/tags/Database/"}]}],"categories":[{"name":"Interview","slug":"Interview","permalink":"http://1.15.107.122/categories/Interview/"},{"name":"Redis","slug":"Redis","permalink":"http://1.15.107.122/categories/Redis/"},{"name":"面试","slug":"面试","permalink":"http://1.15.107.122/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Database","slug":"Database","permalink":"http://1.15.107.122/categories/Database/"},{"name":"ComputerScience","slug":"ComputerScience","permalink":"http://1.15.107.122/categories/ComputerScience/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://1.15.107.122/tags/Go/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://1.15.107.122/tags/NoSQL/"},{"name":"Database","slug":"Database","permalink":"http://1.15.107.122/tags/Database/"},{"name":"Python","slug":"Python","permalink":"http://1.15.107.122/tags/Python/"},{"name":"面试","slug":"面试","permalink":"http://1.15.107.122/tags/%E9%9D%A2%E8%AF%95/"},{"name":"CS","slug":"CS","permalink":"http://1.15.107.122/tags/CS/"}]}